<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.2">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.2">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.2">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.2" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.2">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="机器学习的三大部分一般包括模型、策略和算法，模型是指所选的机器学习算法应该具有某种特性或表达形式，策略是指如何从模型中选择出需要优化的目标函数，而算法则是使用什么优化算法来求解。就我个人的理解，模型和算法通过策略（优化的目标函数）间接关联，其本身有一定的独立性。本篇文章将结合模型、策略和算法介绍无监督学习问题中常用的一些聚类算法，包括但不限于机器学习十大经典算法中的EM算法和K-Means算法。">
<meta name="keywords" content="无监督学习,聚类算法,EM,GMM,K-Means">
<meta property="og:type" content="article">
<meta property="og:title" content="无监督学习中的聚类算法">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2016&#x2F;07&#x2F;21&#x2F;%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&#x2F;index.html">
<meta property="og:site_name" content="Cyliuu&#39;s Learning Blog">
<meta property="og:description" content="机器学习的三大部分一般包括模型、策略和算法，模型是指所选的机器学习算法应该具有某种特性或表达形式，策略是指如何从模型中选择出需要优化的目标函数，而算法则是使用什么优化算法来求解。就我个人的理解，模型和算法通过策略（优化的目标函数）间接关联，其本身有一定的独立性。本篇文章将结合模型、策略和算法介绍无监督学习问题中常用的一些聚类算法，包括但不限于机器学习十大经典算法中的EM算法和K-Means算法。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-10-20T13:37:06.833Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2016/07/21/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>无监督学习中的聚类算法 | Cyliuu's Learning Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cyliuu's Learning Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Machine Learning and Computer Vision</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/07/21/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Cyliuu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cyliuu's Learning Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          无监督学习中的聚类算法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-07-21 22:00:00" itemprop="dateCreated datePublished" datetime="2016-07-21T22:00:00+08:00">2016-07-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-10-20 21:37:06" itemprop="dateModified" datetime="2019-10-20T21:37:06+08:00">2019-10-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>机器学习的三大部分一般包括模型、策略和算法，模型是指所选的机器学习算法应该具有某种特性或表达形式，策略是指如何从模型中选择出需要优化的目标函数，而算法则是使用什么优化算法来求解。就我个人的理解，模型和算法通过策略（优化的目标函数）间接关联，其本身有一定的独立性。<br>本篇文章将结合模型、策略和算法介绍无监督学习问题中常用的一些聚类算法，包括但不限于机器学习十大经典算法中的EM算法和K-Means算法。</p>
<h2 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h2><h3 id="模型说明"><a href="#模型说明" class="headerlink" title="模型说明"></a>模型说明</h3><p>考虑一个参数估计问题，现有$n$个训练样本$\lbrace y_1,y_2,\ldots,y_n \rbrace \in Y$，需要用多个参数$\theta$去拟合数据，那么这个问题的似然函数为</p>
<script type="math/tex; mode=display">\begin{equation}
l(\theta)=\log P(Y\mid\theta)=\sum_{j=1}^n\log P(y_j\mid\theta)
\end{equation}</script><p>此时模型的目标函数为</p>
<script type="math/tex; mode=display">\begin{equation}
\widehat{\theta} = \arg \max_{\theta} l(\theta)
\end{equation}</script><h3 id="算法推导"><a href="#算法推导" class="headerlink" title="算法推导"></a>算法推导</h3><p>由于$\theta$所表示的多个参数可能存在某种关系，导致上面的$\log$似然函数无法直接或者用梯度下降法求出最大值时的$\theta$值，因此需要引入隐变量$Z$来简化$l(\theta)$，使我们能够通过迭代的方法来求解出最优的$\theta$。<br>引入隐变量$Z$后，假设$Q(z)$是关于$z$的某种分布，则似然函数变为</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
l(\theta) &= \sum_{j=1}^{n} \log \sum_{i=1}^k P(y_{j},z_{i} \mid \theta) \\
&= \sum_{j=1}^{n} \log \sum_{i=1}^k Q_{j}(z_{i})\frac{P(y_{j},z_{i}\mid \theta )}{Q_{j}(z_{i})} \\
& \geq \sum_{j=1}^{n} \sum_{i=1}^k Q_{j}(z_{i})\log \frac{P(y_{j},z_{i}\mid \theta )}{Q_{j}(z_{i})}
\end{split}
\end{equation}</script><p>此处用到了Jensen不等式</p>
<blockquote>
<p>如果$f$是上凸函数，$X$是随机变量，那么$f(E[X]) \geq E[f(X)]$<br>特别地，如果$f$是严格上凸函数，那么$f(E[X])=E[f(X)]$当且仅当$X=E[X]$时成立，也就是说$X$是常量。</p>
</blockquote>
<p>公式中$\sum_{i=1}^k Q_j(z_i)\frac{P(y_j,z_i|\theta)}{Q_j(z_i)}$就是$[\frac{P(y_j,z_i|\theta)}{Q_j(z_i)}]$的期望值，而$\log$为上凸函数，因此若$\frac{P(y_j,z_i|\theta)}{Q_j(z_i)}=c$，则似然函数可以转化为</p>
<script type="math/tex; mode=display">\begin{equation}
l(\theta) = \sum_{j=1}^{n} \sum_{i=1}^k Q_{j}(z_{i})\log \frac{P(y_{j},z_{i}\mid \theta )}{Q_{j}(z_{i})}
\end{equation}</script><p>此时目标函数就能够用迭代的方法求出最优值，此时我们的问题就只剩下$Q_{j}(z_{i})$怎么求了，根据$\sum_{i=1}^k Q_{j}(z_{i})=1$，我们有</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
Q_j(z_i) &= \frac{P(y_j,z_i \mid \theta)}{c} \\
&= \frac{P(y_j,z_i \mid \theta)}{\sum_{i=1}^k P(y_j,z_i \mid \theta)} \\
&= \frac{P(y_j,z_i \mid \theta)}{P(y_j \mid \theta)} \\
&= P(z_j \mid y_i,\theta)
\end{split}
\end{equation}</script><h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><h4 id="形式1"><a href="#形式1" class="headerlink" title="形式1"></a>形式1</h4><blockquote>
<p>选取初始值$\theta_0$初始化$\theta$，$t=0$<br>Repeat{<br>E步：Expectation</p>
<script type="math/tex; mode=display">\begin{equation}
Q_j^t(z_i) = P(z_j \mid y_i,\theta^t)
\end{equation}</script><p>M步：Maximization</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\theta^{t+1} &= \arg \max_{\theta} \sum_{j=1}^{n} \sum_{i=1}^k Q_{j}^t(z_{i})\log \frac{P(y_{j},z_{i}\mid \theta )}{Q_{j}^t(z_{i})}\\
t &= t+1
\end{split}
\end{equation}</script><p>}直到收敛</p>
</blockquote>
<h4 id="形式2"><a href="#形式2" class="headerlink" title="形式2"></a>形式2</h4><blockquote>
<p>选取初始值$\theta_0$初始化$\theta$，$t=0$<br>Repeat{<br>E步：Expectation</p>
<script type="math/tex; mode=display">\begin{equation}
H(\theta,\theta^t) =\sum_{z=1}^k P(Z\mid Y,\theta ^{t})\log P(Y,Z\mid \theta )
\end{equation}</script><p>M步：Maximization</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\theta^{t+1} &= \arg \max_{\theta} H(\theta,\theta^t) \\
t &= t+1
\end{split}
\end{equation}</script><p>}直到收敛</p>
</blockquote>
<h3 id="算法优缺点"><a href="#算法优缺点" class="headerlink" title="算法优缺点"></a>算法优缺点</h3><p>只要有一些训练数据，再定义一个最大化函数，采用EM算法，利用计算机经过若干次迭代，就可以得到所需的模型。EM算法是自收敛的分类算法，既不需要事先设定类别也不需要数据见的两两比较合并等操作。缺点是当所要优化的函数不是凸函数时，EM算法容易给出局部最佳解，而不是最优解。</p>
<h2 id="EM算法的应用实例—高斯混合模型（GMM）的参数估计"><a href="#EM算法的应用实例—高斯混合模型（GMM）的参数估计" class="headerlink" title="EM算法的应用实例—高斯混合模型（GMM）的参数估计"></a>EM算法的应用实例—高斯混合模型（GMM）的参数估计</h2><h3 id="模型说明-1"><a href="#模型说明-1" class="headerlink" title="模型说明"></a>模型说明</h3><p>EM算法一般用于解决参数估计问题，无法独立解决实际问题。而GMM作为K个GSM的叠加，本质上属于一个参数估计问题。<br>对于单高斯模型，有</p>
<script type="math/tex; mode=display">\begin{equation}
\phi \left ( y\mid \theta \right )= \frac{1}{\sqrt{2\pi }\sigma }\exp\left ( -\frac{\left ( y-\mu  \right )^{2}}{2\sigma^{2}} \right )
\end{equation}</script><p>对于高斯混合模型，有</p>
<script type="math/tex; mode=display">\begin{equation}
P(y\mid \theta )=\sum_{k=1}^{K}\alpha_{k}\phi (y\mid \theta_{k})
\end{equation}</script><p>在这里，$\theta$包括3类参数$\alpha$，$\mu$和$\sigma$。</p>
<blockquote>
<p>对于一组数据$N_1,N_2,\ldots,N_k$且$N_1+N_2+\ldots+N_k=N$，如果我们事先知道数据的分类情况，那么它的三类参数就能表示为</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\alpha_{k}&=N_{k}/N \\
\mu_{k}&=\frac{1}{N_{k}}\sum_{y\in S(k)}y \\
\sigma_{k}&=\frac{1}{N_{k}}\sum_{y\in S(k)}(y-\mu_{k} )^{2}
\end{split}
\end{equation}</script></blockquote>
<p>而实际情况是我们只知道数据的观测值，需要根据观测值推测出数据的分类情况。<br>高斯混合模型给出了$P(y \mid \theta)$的假设，之后利用EM算法的思路，将参数估计问题转换成求解极大似然函数的极值点的问题，最后引入隐变量通过迭代方法求出最优值。</p>
<h3 id="算法推导-1"><a href="#算法推导-1" class="headerlink" title="算法推导"></a>算法推导</h3><p>对于一个高斯混合模型，假设它由$K$个单高斯模型组合而成，我们引入一个变量$\gamma_{jk}$，表示的是第$j$个观测数据来自第$k$类的概率，那么</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\gamma_{jk}&=P(z_{k}\mid y_{j},\theta ) \\
& =\frac{P(z_{k},y_{j}\mid \theta )}{P(y_{j}\mid \theta )} \\
& =\frac{P(z_{k},y_{j}\mid \theta )}{\sum_{k=1}^{K}P(z_{k},y_{j}\mid \theta )} \\
& =\frac{P(y_{j}\mid z_{k},\theta )P(z_{k}\mid \theta )}{\sum_{k=1}^{K}P(y_{j}\mid z_{k},\theta )P(z_{k}\mid \theta)} \\
& =\frac{\alpha_{k}\phi (y_{j}\mid \theta_{k})}{\sum_{k=1}^{K}\alpha_{k}\phi (y_{j}\mid \theta_{k})}
\end{split}
\end{equation}</script><p>这里对应于EM算法中的E步骤，$\gamma_{jk}$实际上就是EM算法原型中的$Q_j(z_i)$，只不过现在给出了它的实际意义。<br>因此在已知观测值的情况下，它的三类参数就可以表示为</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\alpha_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}}{N} \\
\mu_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}y_{j}}{\sum_{j=1}^{N} \gamma_{jk}} \\
\sigma^{2}_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}(y_{j}-\mu_{k})^{2}}{\sum_{j=1}^{N} \gamma_{jk}}
\end{split}
\end{equation}</script><p>这里对应于EM算法中的M步骤，混合高斯模型的三类参数实际上就是对极大似然函数求偏导的结果。</p>
<h3 id="算法步骤-1"><a href="#算法步骤-1" class="headerlink" title="算法步骤"></a>算法步骤</h3><h4 id="形式1-1"><a href="#形式1-1" class="headerlink" title="形式1"></a>形式1</h4><blockquote>
<p>选取初始值初始化$\theta$<br>重复{<br>E步：Expectation</p>
<script type="math/tex; mode=display">\begin{equation}
\gamma_{jk}=\frac{\alpha_{k}\phi (y_{j}\mid \theta_{k})}{\sum_{k=1}^{K}\alpha_{k}\phi (y_{j}\mid \theta_{k})}
\end{equation}</script><p>M步：Maximization</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\alpha_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}}{N} \\
\mu_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}y_{j}}{\sum_{j=1}^{N} \gamma_{jk}} \\
\sigma^{2}_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}(y_{j}-\mu_{k})^{2}}{\sum_{j=1}^{N} \gamma_{jk}}
\end{split}
\end{equation}</script><p>}直到收敛</p>
</blockquote>
<h4 id="形式2-1"><a href="#形式2-1" class="headerlink" title="形式2"></a>形式2</h4><blockquote>
<p>选取初始值初始化$\theta$<br>重复{<br>E步：Expectation</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
 H(\theta ,\theta ^{t}) &= \sum_{j=1}^{N}\sum_{k=1}^{K}\gamma_{jk}\log\frac{\alpha_{k}\phi  (y_{j}\mid \theta_{k})}{\gamma_{jk}} \\
& =\sum_{j=1}^{N}\sum_{k=1}^{K}\gamma_{jk}\log\frac{\frac{1}{\sqrt{2\pi }\sigma }\exp\left ( -\frac{\left ( y-\mu  \right )^{2}}{2\sigma^{2}} \right )}{\gamma_{jk}}\\
& =\sum_{j=1}^{N}\sum_{k=1}^{K}\gamma_{jk}\left [\log \alpha_{k} +\log \left ( \frac{1}{\sqrt{2\pi }} \right ) -\log \sigma_{k}-\frac{(y-\mu )^{2}}{2\sigma_{k}^{2}}-\log\gamma_{jk} \right ]
\end{split}
\end{equation}</script><p>M步：Maximization<br>根据$H(\theta ,\theta ^{t})$和$\alpha_k \geq 0, \sum_{k=1}^K \alpha_k = 1$构造出$L(\theta)$<br>由</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\frac{ \partial L(\theta) }{\partial \alpha_{k}} &= 0 \\
\frac{ \partial L(\theta) }{\partial \lambda} &= 0 \\
\frac{\partial H(\theta, \theta^t)}{\partial\mu_k} &= 0 \\
\frac{\partial H(\theta, \theta^t)}{\partial\sigma_k} &= 0
\end{split}
\end{equation}</script><p>得出</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
\alpha_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}}{N} \\
\mu_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}y_{j}}{\sum_{j=1}^{N} \gamma_{jk}} \\
\sigma^{2}_{k}&=\frac{\sum_{j=1}^{N} \gamma_{jk}(y_{j}-\mu_{k})^{2}}{\sum_{j=1}^{N} \gamma_{jk}}
\end{split}
\end{equation}</script><p>}直到收敛</p>
</blockquote>
<h2 id="K-Means算法"><a href="#K-Means算法" class="headerlink" title="K-Means算法"></a>K-Means算法</h2><h3 id="算法推导-2"><a href="#算法推导-2" class="headerlink" title="算法推导"></a>算法推导</h3><p>EM算法是利用相互迭代的思路求解最优值，同样利用迭代思想的还包括K-Means聚类算法。<br>K-Means算法定义了一个损失函数</p>
<script type="math/tex; mode=display">\begin{equation}
J=\sum_{n=1}^N \sum_{k=1}^K r_{nk}\left|\left|x_n-\mu_k \right| \right|^2
\end{equation}</script><p>此时模型的目标函数为</p>
<script type="math/tex; mode=display">\begin{equation}
[\widehat r,\widehat \mu]=\arg \min J
\end{equation}</script><p>与高斯混合模型中的目标函数相比，K-Mean算法的损失函数$r_{nk}\in \lbrace0,1\rbrace$，而似然函数的$\gamma_{jk}\in \left[0,1\right]$，当然还有其他比较明显的区别如K-Means是求和而GMM是对数求和，这与问题模型本身的性质有关。<br>K-Means算法中，我们的目标是找到合适的$r_{nk}$和$\mu_k$使损失函数最小，可以采用类似于EM算法的迭代思路来求解。首先，我们为$\mu_k$选择一些初始值。然后，在第一阶段，我们关于$r_{nk}$最小化$J$，保持$\mu_k$固定。在第二阶段，我们关于$\mu_k$最小化$J$，保持$r_{nk}$固定。不断重复这两个阶段优化直到收敛。我们会看到，更新$r_{nk}$和更新$\mu_k$的两个阶段分别对应于EM算法中的E（期望）步骤和M（最大化）步骤。<br>首先考虑确定$r_{nk}$。由于$J$是关于$r_{nk}$的一个线性函数，而不同的$n$（即样本）之间相互独立，因此我们可以对每个$n$分别进行最优化，只要$k$的值使$\left|\left|x_n-\mu_k \right| \right|^2$最小，我们就令$r_{nk}$等于1。换句话说，我们可以将数据点的聚类设置为最近的聚类中心。更形式化地，这可以表达为</p>
<script type="math/tex; mode=display">\begin{equation}
\ r_{nk}=\begin{cases} 1，如果k=\arg min_j\left|\left|x_n-\mu_j \right| \right|^2\\ 0，其他情况\end{cases}
\end{equation}</script><p>然后考虑$r_{nk}$固定时，关于$\mu_k$的最优化。目标函数$J$是$\mu_k$的一个二次函数，对其求偏导可以解出</p>
<script type="math/tex; mode=display">\begin{equation}
\mu_k=\frac {\sum_{n} r_{nk}x_{n}}{\sum_n r_{nk}}
\end{equation}</script><h3 id="算法步骤-2"><a href="#算法步骤-2" class="headerlink" title="算法步骤"></a>算法步骤</h3><blockquote>
<p>初始化：首先选择$K$个随机的点，称为聚类中心（cluster centroids）<br>Repeat{<br>（1）对于数据集中的每一个，按照距离与$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类<br>（2）计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置<br>}直到收敛</p>
</blockquote>
<h3 id="与高斯混合模型的异同点"><a href="#与高斯混合模型的异同点" class="headerlink" title="与高斯混合模型的异同点"></a>与高斯混合模型的异同点</h3><h4 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h4><p>（1）需要指定$K$值。<br>（2）需要指定初始值，例如K-Means的中心点，GMM的各个参数。<br>（3）都是含有EM算法思想。</p>
<h4 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h4><p>（1）优化目标函数不同，K-Means：最短距离，GMM：最大化$\log$似然估计。<br>（2）E步的指标不同，K-Means：点到聚类中心的距离（硬指标），GMM：求解每个观测数据属于每一类的概率（软指标）。</p>
<h3 id="算法优缺点-1"><a href="#算法优缺点-1" class="headerlink" title="算法优缺点"></a>算法优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>（1）是解决聚类问题的一种经典算法，简单、快速。<br>（2）对处理大数据集，该算法是相对可伸缩和高效率的。<br>（3）当类内数据密集，而类间数据区别明显时, 它的效果较好。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>（1）在类的平均值被定义的情况下才能使用，这对于处理符号属性的数据不适用。<br>（2）必须事先给出$K$（要生成的类的数目），而且对初值敏感，对于不同的初始值，可能会导致不同结果。<br>（3）它对于“躁声”和孤立点数据是敏感的，少量的该类数据能够对平均值产生极大的影响。</p>
<h4 id="K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为"><a href="#K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为" class="headerlink" title="K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为"></a>K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为</h4><p>（1）多设置一些不同的初值，对比最后的运算结果，直到结果趋于稳定结束。<br>（2）绘出损失函数$J$关于类数$K$的曲线，利用”肘部法则“确定合适的$K$值。</p>
<h2 id="其他聚类算法"><a href="#其他聚类算法" class="headerlink" title="其他聚类算法"></a>其他聚类算法</h2><h3 id="K-Medoids聚类"><a href="#K-Medoids聚类" class="headerlink" title="K-Medoids聚类"></a>K-Medoids聚类</h3><p>K-Means算法的基础是将平方欧几里得距离作为数据点与代表向量之间不相似程度的度量。这不仅限制了能够处理的数据变量的类型（例如，它不能处理某些或全部变量表示类别标签的情形），而且使得聚类中心的确定对于异常点不具有鲁棒性。我们可以这样推广K-Means算法：引入两个向量$x$和$x’$之间的一个更加一般的不相似程度的度量$\nu(x,x’)$，然后最小化下面的损失函数</p>
<script type="math/tex; mode=display">\begin{equation}
J=\sum_{n=1}^N \sum_{k=1}^K r_{nk}\nu(x_{n},\mu_{k})
\end{equation}</script><h3 id="Spectral聚类"><a href="#Spectral聚类" class="headerlink" title="Spectral聚类"></a>Spectral聚类</h3><p>Spectral聚类的思想是将样本看作顶点，样本间的相似度看作带权的边，从而将聚类问题转为图分割问题：找到一种图分割的方法使得连接不同组的边的权重尽可能低，组内的边的权重尽可能高。<br>图分割问题可以定义为最小化以下目标函数</p>
<script type="math/tex; mode=display">\begin{equation}
cut(A_{1},A_{2},\ldots,A{k})=\frac{1}{2}\sum_{i=1}^{k}W(A_{i},\overline {A_{i}})
\end{equation}</script><p>其中$k$表示分成$k$个组，$A_{i}$表示第$i$个组，$W(A,B)$表示第$A$组与第$B$组之间的所有边的权重之和。<br>为保证每个类都有合理的大小，我们将目标函数调整为</p>
<script type="math/tex; mode=display">\begin{equation}
\begin{split}
RatioCut(A_{1},A_{2},\ldots,A{k})&=\frac{1}{2}\sum_{i=1}^{k}\frac{W(A_{i},\overline {A_{i}})}{\left|A_{i}\right|}\\
&=\sum_{i=1}^{k}\frac{cut(A_{i},\overline {A_{i}})}{\left|A_{i}\right|}
\end{split}
\end{equation}</script><h3 id="Meanshift聚类"><a href="#Meanshift聚类" class="headerlink" title="Meanshift聚类"></a>Meanshift聚类</h3><p>MeanShift算法是一种非参数聚类技术，它不要求预先知道聚类的类别个数，对聚类的形状也没有限制。<br>在$d$维空间$R_{d}$中，给定$n$个数据点$x_{i}$，由核函数$K(x)$和窗口半径$h$得到的多元核密度估计函数为</p>
<script type="math/tex; mode=display">\begin{equation}
f(x)=\frac{1}{nh^d} \sum_{i=1}^n K(\frac{x-x_{i}}{h})
\end{equation}</script><p>其中</p>
<script type="math/tex; mode=display">\begin{equation}
K(x)=c_{k,d}k(\left|\left| x\right|\right|^{2})
\end{equation}</script><p>目标函数可以理解为</p>
<script type="math/tex; mode=display">\begin{equation}
\widehat{x} = \arg \max_{x} f(x)
\end{equation}</script><p>对$f(x)$求导</p>
<script type="math/tex; mode=display">\begin{equation}
\nabla f(x)=\frac{2c_{k,d}}{nh^{d+2}}\sum_{i=1}^{n}(x_{i}-x)g(\left|\left| \frac{x-x_{i}}{h}\right|\right|^{2})=0
\end{equation}</script><p>得出</p>
<script type="math/tex; mode=display">\begin{equation}
x=\frac{\sum_{i=1}^{n}x_{i}g(\left|\left| \frac{x-x_{i}}{h}\right|\right|^{2})}  {\sum_{i=1}^{n}g(\left|\left| \frac{x-x_{i}}{h}\right|\right|^{2})}
\end{equation}</script><p>令$g(x)=1$，发现$x=\frac{1}{n}\sum_{i=1}^{n}x_{i}$，那么</p>
<script type="math/tex; mode=display">\begin{equation}
m_{h}(x)=\frac{\sum_{i=1}^{n}x_{i}g(\left|\left| \frac{x-x_{i}}{h}\right|\right|^{2})}  {\sum_{i=1}^{n}g(\left|\left| \frac{x-x_{i}}{h}\right|\right|^{2})}-x
\end{equation}</script><p>反映的是样本均值的偏移量，即Meanshift向量。</p>
<blockquote>
<p>初始化：首先选择$K$个随机的点，称为聚类中心（cluster centroids）<br>Repeat{<br>（1）根据窗口半径$h$重新聚类以计算$m_{h}(x^{t})$<br>（2）平移窗口$x^{t+1}=x^{t}+m_{h}(x^{t})$<br>}直到收敛</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag"># 无监督学习</a>
              <a href="/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" rel="tag"># 聚类算法</a>
              <a href="/tags/EM/" rel="tag"># EM</a>
              <a href="/tags/GMM/" rel="tag"># GMM</a>
              <a href="/tags/K-Means/" rel="tag"># K-Means</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2016/07/21/%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E7%9A%84%E7%AE%97%E6%B3%95/" rel="next" title="基于实例的算法--KNN分类器">
                  <i class="fa fa-chevron-left"></i> 基于实例的算法--KNN分类器
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#EM算法"><span class="nav-number">1.</span> <span class="nav-text">EM算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型说明"><span class="nav-number">1.1.</span> <span class="nav-text">模型说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法推导"><span class="nav-number">1.2.</span> <span class="nav-text">算法推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法步骤"><span class="nav-number">1.3.</span> <span class="nav-text">算法步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#形式1"><span class="nav-number">1.3.1.</span> <span class="nav-text">形式1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#形式2"><span class="nav-number">1.3.2.</span> <span class="nav-text">形式2</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法优缺点"><span class="nav-number">1.4.</span> <span class="nav-text">算法优缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EM算法的应用实例—高斯混合模型（GMM）的参数估计"><span class="nav-number">2.</span> <span class="nav-text">EM算法的应用实例—高斯混合模型（GMM）的参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型说明-1"><span class="nav-number">2.1.</span> <span class="nav-text">模型说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法推导-1"><span class="nav-number">2.2.</span> <span class="nav-text">算法推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法步骤-1"><span class="nav-number">2.3.</span> <span class="nav-text">算法步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#形式1-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">形式1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#形式2-1"><span class="nav-number">2.3.2.</span> <span class="nav-text">形式2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K-Means算法"><span class="nav-number">3.</span> <span class="nav-text">K-Means算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#算法推导-2"><span class="nav-number">3.1.</span> <span class="nav-text">算法推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法步骤-2"><span class="nav-number">3.2.</span> <span class="nav-text">算法步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#与高斯混合模型的异同点"><span class="nav-number">3.3.</span> <span class="nav-text">与高斯混合模型的异同点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#相同点"><span class="nav-number">3.3.1.</span> <span class="nav-text">相同点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#不同点"><span class="nav-number">3.3.2.</span> <span class="nav-text">不同点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法优缺点-1"><span class="nav-number">3.4.</span> <span class="nav-text">算法优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#优点"><span class="nav-number">3.4.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缺点"><span class="nav-number">3.4.2.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为"><span class="nav-number">3.4.3.</span> <span class="nav-text">K-Means算法对于不同的初始值和类数，可能会导致不同结果，解决方法为</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他聚类算法"><span class="nav-number">4.</span> <span class="nav-text">其他聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Medoids聚类"><span class="nav-number">4.1.</span> <span class="nav-text">K-Medoids聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spectral聚类"><span class="nav-number">4.2.</span> <span class="nav-text">Spectral聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Meanshift聚类"><span class="nav-number">4.3.</span> <span class="nav-text">Meanshift聚类</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Cyliuu"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Cyliuu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/cyliuu" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;cyliuu" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lcy940903@gmail.com" title="E-Mail &amp;rarr; mailto:lcy940903@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/243339151" title="Weibo &amp;rarr; https:&#x2F;&#x2F;weibo.com&#x2F;243339151" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/cyliuu" title="Instagram &amp;rarr; https:&#x2F;&#x2F;instagram.com&#x2F;cyliuu" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cyliuu</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">15k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">13 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.2
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.2"></script><script src="/js/motion.js?v=7.4.2"></script>
<script src="/js/schemes/pisces.js?v=7.4.2"></script>
<script src="/js/next-boot.js?v=7.4.2"></script>



  






  <script src="/js/local-search.js?v=7.4.2"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

  

</body>
</html>
